{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is concerned to ML Bootcamp Competition 2023 for Ukrainians which was carried out in August 2023\n",
    "### Instruments used in this NN are purely got from free bootcamp \"Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\"\n",
    "### Workout plan:\n",
    "##### 1.Explore images and get aquainted with yoga poses\n",
    "##### 2.Preprocess images: remove bachground and crop human pose to the centre of image\n",
    "##### 3.Workout with simple NN moder in order to get approximate hyperparameters that gives satisfactory results\n",
    "##### 4.Implement Inception model and train it with several variations of hyperparameters (got in i.3) in order to get different prediction results\n",
    "##### 5.Concatenate those predictions (got in i.4) using soft votes and predict test images\n",
    "##### 6.Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageChops\n",
    "from rembg import remove\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## define direcotry with images and labels\n",
    "TRAIN_IMAGES_DIRECTORY = 'images/train_images/'\n",
    "TEST_IMAGES_DIRECTORY = 'images/test_images/'\n",
    "TRAIN_LABELS_CSV = 'train.csv'\n",
    "RESOLUTION = 200\n",
    "\n",
    "## function that trim free space at image and position the image in the centre of picture\n",
    "def trim(im):\n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = list(diff.getbbox())\n",
    "    if bbox:\n",
    "        if bbox[2]-bbox[0] != bbox[3]-bbox[1]:\n",
    "            add_space = (bbox[2]-bbox[0])-(bbox[3]-bbox[1])\n",
    "            if add_space > 0:\n",
    "                bbox[3] += int(add_space/2)\n",
    "                bbox[1] -= int(add_space/2)\n",
    "            else:\n",
    "                bbox[0] += int(add_space/2)\n",
    "                bbox[2] -= int(add_space/2) \n",
    "        return im.crop(bbox)\n",
    "\n",
    "## function that removes background from pictures and converts them to np.array (4dim format). Returns tuple of numpy array of images and their ids\n",
    "def img_to_arr_crop(directory, resolution, img_list = [], img_format = '.jpg'):\n",
    "    res_list = []\n",
    "    if img_list == []:\n",
    "        img_list = [i for i in os.listdir(directory) if i[-4:] == img_format]\n",
    "    for i in img_list:\n",
    "        curr_image = np.asarray(trim(remove(Image.open(directory+i))).resize((resolution, resolution)))\n",
    "        if len(curr_image.shape) < 3:\n",
    "            curr_image = np.asarray(trim(remove(Image.open(directory+i))).resize((resolution, resolution)).convert('RGB'))\n",
    "        res_list.append(curr_image)\n",
    "    res_images = np.array(res_list).astype(float)\n",
    "    return res_images, img_list\n",
    "\n",
    "## function for plotting fitting results\n",
    "def plot_learning_results(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "## function for training a model\n",
    "def fitting_model(hyperparameters):\n",
    "    ## define a model and its structure before fitting\n",
    "    pre_trained_model = tf.keras.applications.InceptionV3(input_shape = (hyperparameters['RESOLUTION'], hyperparameters['RESOLUTION'], 3), \n",
    "                                                        include_top = False, \n",
    "                                                        weights = 'imagenet')\n",
    "\n",
    "    for layer in pre_trained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    last_layer = pre_trained_model.get_layer(hyperparameters['layer'])\n",
    "    last_output = last_layer.output\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(last_output)\n",
    "    x = tf.keras.layers.Dropout(hyperparameters['dropout'])(x)    \n",
    "    x = tf.keras.layers.Dense(hyperparameters['Dense'], activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(hyperparameters['dropout'])(x)    \n",
    "    x = tf.keras.layers.Dense (6,activation='softmax')(x)           \n",
    "\n",
    "    model = tf.keras.Model(pre_trained_model.input, x) \n",
    "    loss_f = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparameters['lr']), \n",
    "                    loss = loss_f, \n",
    "                    metrics = ['accuracy'])\n",
    "\n",
    "    ## split values on training ang validation\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(training_images[:,:,:,:3], lbl_list, test_size=hyperparameters['val_split'], stratify = lbl_list)\n",
    "\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                                                    width_shift_range=hyperparameters['width_shift_range'],\n",
    "                                                                    height_shift_range=hyperparameters['height_shift_range'],\n",
    "                                                                    rotation_range=hyperparameters['rotation_range'],\n",
    "                                                                    shear_range=hyperparameters['shear_range'],\n",
    "                                                                    zoom_range=hyperparameters['zoom_range'],\n",
    "                                                                    fill_mode=hyperparameters['fill_mode'],\n",
    "                                                                    horizontal_flip=hyperparameters['horizontal_flip'],\n",
    "                                                                    )\n",
    "\n",
    "    train_generator = train_datagen.flow(x = X_train,\n",
    "                                        y=y_train,\n",
    "                                        batch_size=hyperparameters['batch_size_t'],\n",
    "                                        shuffle = hyperparameters['shuffle'])\n",
    "\n",
    "    validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                                                        validation_split=hyperparameters['val_split']\n",
    "                                                                        )\n",
    "\n",
    "    validation_generator = validation_datagen.flow(x = X_val,\n",
    "                                                    y=y_val,\n",
    "                                                    batch_size=hyperparameters['batch_size_v'],\n",
    "                                                    shuffle = hyperparameters['shuffle'])\n",
    "\n",
    "    ## fitting model\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs=hyperparameters['epochs'],\n",
    "                        validation_data=validation_generator)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create lists of labels and images\n",
    "df  = pd.read_csv(TRAIN_LABELS_CSV)\n",
    "img_list = list(df['image_id'])\n",
    "lbl_list = list(df['class_6'])\n",
    "\n",
    "## converting images: takes around 2 sec per image\n",
    "training_images = img_to_arr_crop(TRAIN_IMAGES_DIRECTORY, RESOLUTION, img_list)[0] ## no need to get ids, because it was done on previous step\n",
    "testing_images, testing_labels = img_to_arr_crop(TEST_IMAGES_DIRECTORY, RESOLUTION)\n",
    "\n",
    "## show random image before and after processing\n",
    "test_example_image = np.random.randint(len(training_images))\n",
    "example_image = img_list[test_example_image]\n",
    "print('image: ', example_image)\n",
    "old_img = np.asarray(Image.open(TRAIN_IMAGES_DIRECTORY+example_image))\n",
    "plt.imshow(old_img.astype('uint8'))\n",
    "plt.show()\n",
    "new_img = training_images[test_example_image]\n",
    "plt.imshow(new_img.astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save & load preprocessing results\n",
    "#### In case we want to postpone workout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"all_training_images.npy\", training_images)\n",
    "np.save(\"all_training_labels.npy\", np.array(lbl_list))\n",
    "np.save(\"all_training_ids.npy\", np.array(img_list))\n",
    "np.save(\"all_testing_images.npy\", testing_images)\n",
    "np.save(\"all_testing_labels.npy\", np.array(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = np.load(\"all_training_images.npy\")\n",
    "lbl_list = list(np.load(\"all_training_labels.npy\"))\n",
    "img_list = list(np.load(\"all_training_ids.npy\"))\n",
    "testing_images = np.load(\"all_testing_images.npy\")\n",
    "testing_labels = list(np.load(\"all_testing_labels.npy\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN workout \n",
    "#### with the aim to get satisfying hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'val_split':0.15, \n",
    "                'RESOLUTION':RESOLUTION, \n",
    "                'width_shift_range':0.05, \n",
    "                'height_shift_range':0.05,\n",
    "                'zoom_range':0.05, \n",
    "                'fill_mode':'nearest', \n",
    "                'horizontal_flip':True,\n",
    "                'shuffle':True,\n",
    "                'batch_size_t':32,\n",
    "                'batch_size_v':8,\n",
    "                'Conv2D_1':16,\n",
    "                'Conv2D_2':16,\n",
    "                'Conv2D_3':16,\n",
    "                'Dense':128,\n",
    "                'epochs':50,\n",
    "                'loss':'sparse_categorical_crossentropy',\n",
    "                'optimizer':'Adam',\n",
    "                'lr':0.0005,\n",
    "                'dropout':0.45}\n",
    "\n",
    "def train_simple_model(hyperparameters):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(training_images, lbl_list, test_size=hyperparameters['val_split'], stratify = lbl_list)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                         width_shift_range=hyperparameters['width_shift_range'],\n",
    "                                         height_shift_range=hyperparameters['height_shift_range'],\n",
    "                                         zoom_range=hyperparameters['zoom_range'],\n",
    "                                         fill_mode=hyperparameters['fill_mode'],\n",
    "                                         horizontal_flip=hyperparameters['horizontal_flip'],\n",
    "                                         )\n",
    "    train_generator = train_datagen.flow(x=X_train,\n",
    "                                        y=y_train,\n",
    "                                        shuffle = hyperparameters['shuffle'],\n",
    "                                        batch_size=hyperparameters['batch_size_t'])\n",
    "    validation_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                              )\n",
    "    validation_generator = validation_datagen.flow(x=X_val,\n",
    "                                                  y=y_val,\n",
    "                                                    shuffle = hyperparameters['shuffle'],\n",
    "                                                  batch_size=hyperparameters['batch_size_v'])\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(hyperparameters['Conv2D_1'],(3,3),activation='relu',input_shape=(hyperparameters['RESOLUTION'],hyperparameters['RESOLUTION'],4)),\n",
    "      tf.keras.layers.MaxPooling2D(3,3),\n",
    "      tf.keras.layers.Conv2D(hyperparameters['Conv2D_2'],(3,3),activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(3,3),      \n",
    "      tf.keras.layers.Conv2D(hyperparameters['Conv2D_3'],(3,3),activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(3,3),\n",
    "      tf.keras.layers.Dropout(hyperparameters['dropout']),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(hyperparameters['Dense'],activation='relu'),\n",
    "      tf.keras.layers.Dense(6,activation='softmax')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparameters['lr'])\n",
    "    model.summary()\n",
    "    model.compile(optimizer = optimizer,\n",
    "                loss = hyperparameters['loss'],\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs=hyperparameters['epochs'],\n",
    "                        validation_data=validation_generator)\n",
    "    \n",
    "    print(hyperparameters)\n",
    "\n",
    "    plot_learning_results(history)\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_simple_model(hyperparameters).save('model_pre_0.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and voting for best result \n",
    "#### Get 3 different results and concatenating them with soft voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting approximate hyperparameters were got after some stages of training \n",
    "hyperparameters={'val_split':0.1, \n",
    "                'layer':'mixed7',\n",
    "                'RESOLUTION':RESOLUTION, \n",
    "                'width_shift_range':0.1, \n",
    "                'height_shift_range':0.1,\n",
    "                'zoom_range':0.1,\n",
    "                'shear_range':0.1,\n",
    "                'rotation_range':10,\n",
    "                'fill_mode':'nearest', \n",
    "                'horizontal_flip':True,\n",
    "                'shuffle':True,\n",
    "                'batch_size_t':8,\n",
    "                'batch_size_v':4,\n",
    "                'Conv2D_1':16,\n",
    "                'Dense':256,\n",
    "                'epochs':20,\n",
    "                'loss':'CategoricalCrossentropy',\n",
    "                'optimizer':'Adam',\n",
    "                'lr':0.0001,\n",
    "                'dropout':0.5}\n",
    "\n",
    "history = fitting_model(hyperparameters)\n",
    "\n",
    "## show fitting results and get predictions\n",
    "print('iter_1: ',hyperparameters)\n",
    "\n",
    "plot_learning_results(history)\n",
    "\n",
    "predictions_iter_1 = model.predict(testing_images[:,:,:,:3])\n",
    "\n",
    "model.save('model_iter_1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting hyperparameters were got after some stages of training \n",
    "hyperparameters={'val_split':0.1, \n",
    "                'layer':'mixed7',\n",
    "                'RESOLUTION':RESOLUTION, \n",
    "                'width_shift_range':0.07, \n",
    "                'height_shift_range':0.07,\n",
    "                'zoom_range':0.07,\n",
    "                'shear_range':0.07,\n",
    "                'rotation_range':7,\n",
    "                'fill_mode':'nearest', \n",
    "                'horizontal_flip':True,\n",
    "                'shuffle':True,\n",
    "                'batch_size_t':16,\n",
    "                'batch_size_v':4,\n",
    "                'Conv2D_1':32,\n",
    "                'Dense':128,\n",
    "                'epochs':15,\n",
    "                'loss':'CategoricalCrossentropy',\n",
    "                'optimizer':'Adam',\n",
    "                'lr':0.0003,\n",
    "                'dropout':0.3}\n",
    "\n",
    "history = fitting_model(hyperparameters)\n",
    "\n",
    "print('iter_2: ',hyperparameters)\n",
    "\n",
    "plot_learning_results(history)\n",
    "\n",
    "predictions_iter_2 = model.predict(testing_images[:,:,:,:3])\n",
    "\n",
    "model.save('model_iter_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting hyperparameters were got after some stages of training \n",
    "hyperparameters={'val_split':0.1, \n",
    "                'layer':'mixed7',\n",
    "                'RESOLUTION':RESOLUTION, \n",
    "                'width_shift_range':0.15, \n",
    "                'height_shift_range':0.15,\n",
    "                'zoom_range':0.15,\n",
    "                'shear_range':0.15,\n",
    "                'rotation_range':15,\n",
    "                'fill_mode':'nearest', \n",
    "                'horizontal_flip':True,\n",
    "                'shuffle':True,\n",
    "                'batch_size_t':32,\n",
    "                'batch_size_v':4,\n",
    "                'Conv2D_1':32,\n",
    "                'Dense':512,\n",
    "                'epochs':15,\n",
    "                'loss':'CategoricalCrossentropy',\n",
    "                'optimizer':'Adam',\n",
    "                'lr':0.0001,\n",
    "                'dropout':0.5}\n",
    "\n",
    "history = fitting_model(hyperparameters)\n",
    "\n",
    "print('iter_3: ',hyperparameters)\n",
    "\n",
    "plot_learning_results(history)\n",
    "\n",
    "predictions_iter_3 = model.predict(testing_images[:,:,:,:3])\n",
    "\n",
    "model.save('model_iter_3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions_iter_1 + predictions_iter_2 + predictions_iter_3\n",
    "df = pd.DataFrame(list(np.argmax(predictions, axis=1)), index=testing_labels).reset_index()\n",
    "df.columns = ['image_id','class_6']\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
